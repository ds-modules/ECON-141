{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econ 141  - Spring 2019\n",
    "\n",
    "## Bryan Graham\n",
    "### GSI Seongjoo Min\n",
    "\n",
    "## Problem Set 2 -  Due February 26th, 2019\n",
    "\n",
    "Problem sets are due at 5PM in the GSIs mailbox. You may work in groups,\n",
    "but each student should turn in their own write-up (including a narrated/commented\n",
    "and executed Jupyter Notebook). Please use markdown boxes within your\n",
    "Jupyter notebook for narrative answers to the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using inverse probability weighting (IPW) to evaluate the returns to a college degree\n",
    "\n",
    "The purpose of this problem set is to give you practice using the basic covariate adjustment methods introduced in lecture. You might find the following papers useful. The paper “Improving middle school quality in poor countries: evidence from the Honduran Sistema de Aprendizaje Tutorial” (McEwan et al., 2015) provides an example of inverse probability weighting in action. You should also review your lectures notes and read Holland (1986), Efron & Hastie (2016, Chapter 8) and Hirano & Imbens (2001).\n",
    "\n",
    "Overview of dataset:\n",
    "\n",
    "This problem set uses the comma delimited dataset [nlsy79extract.csv](https://github.com/bryangraham/Ec_141/blob/master/Spring2019/Datasets/nlsy79extract.csv) available on the [course GitHub page](https://github.com/bryangraham/Ec_141/tree/master/Spring2019). \n",
    "\n",
    "The dataset includes information on 12,686 youth surveyed as part of the National Longitudinal Survey of Youth 1979 (NLSY79). In this problem set you will use the following variables:\n",
    "\n",
    "`core_sample` – indicator for whether individual is part of the core\n",
    "\n",
    "`NLSY70 sample year_born` – year in which individual was born\n",
    "\n",
    "`live_with_mom_at_14` - dummy variable indicating whether individual resided with their mother at age 14\n",
    "\n",
    "`live_with_dad_at_14` – dummy variable indicating whether individual resided with their father at age 14\n",
    "\n",
    "`usborn` - dummy variable indicating whether individual was born in the \n",
    "\n",
    "`United States male` - male/female dummy variable\n",
    "\n",
    "`hispanic` – hispanic/non-hispanic dummy variable\n",
    "￼￼￼￼￼￼￼\n",
    "`black` – black/non-black dummy variable\n",
    "\n",
    "`AFQT` – Armed Forces Qualification Test (AFQT) score percentile (0 to 100)\n",
    "\n",
    "`HGC_Age28` – years of completed school at age 28\n",
    "\n",
    "`HGC_Fath79` – father’s years of completed schooling\n",
    "\n",
    "`HGC_Moth79` – mother’s years of completed schooling\n",
    "\n",
    "`real_earnings_xxxx` – “xxxx” real earnings in 2010 prices (available for multiple years)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "1. The dataset has been loaded below into a pandas dataframe called `nlsy79`. Use `HHID_79` and `PID_79` as the multi-indices for the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID_79</th>\n",
       "      <th>HHID_79</th>\n",
       "      <th>core_sample</th>\n",
       "      <th>sample_wgts</th>\n",
       "      <th>month_born</th>\n",
       "      <th>year_born</th>\n",
       "      <th>live_with_mom_at_14</th>\n",
       "      <th>live_with_dad_at_14</th>\n",
       "      <th>single_mom_at_14</th>\n",
       "      <th>usborn</th>\n",
       "      <th>...</th>\n",
       "      <th>weeks_worked_2001</th>\n",
       "      <th>weeks_worked_2003</th>\n",
       "      <th>weeks_worked_2005</th>\n",
       "      <th>weeks_worked_2007</th>\n",
       "      <th>weeks_worked_2009</th>\n",
       "      <th>weeks_worked_2011</th>\n",
       "      <th>NORTH_EAST_79</th>\n",
       "      <th>NORTH_CENTRAL_79</th>\n",
       "      <th>SOUTH_79</th>\n",
       "      <th>WEST_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>602156.31</td>\n",
       "      <td>9</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>816100.38</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>572996.38</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>604567.88</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>764753.00</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID_79  HHID_79  core_sample  sample_wgts  month_born  year_born  \\\n",
       "0       1        1            1    602156.31           9         58   \n",
       "1       2        2            1    816100.38           1         59   \n",
       "2       3        3            1    572996.38           8         61   \n",
       "3       4        3            1    604567.88           8         62   \n",
       "4       5        5            1    764753.00           7         59   \n",
       "\n",
       "   live_with_mom_at_14  live_with_dad_at_14  single_mom_at_14  usborn  \\\n",
       "0                  1.0                  1.0               0.0     1.0   \n",
       "1                  1.0                  1.0               0.0     0.0   \n",
       "2                  1.0                  0.0               0.0     1.0   \n",
       "3                  1.0                  0.0               0.0     1.0   \n",
       "4                  1.0                  1.0               0.0     1.0   \n",
       "\n",
       "    ...     weeks_worked_2001  weeks_worked_2003  weeks_worked_2005  \\\n",
       "0   ...                   NaN                NaN                NaN   \n",
       "1   ...                   0.0               18.0               52.0   \n",
       "2   ...                   0.0                NaN               43.0   \n",
       "3   ...                   NaN                NaN                NaN   \n",
       "4   ...                   NaN                NaN                NaN   \n",
       "\n",
       "   weeks_worked_2007  weeks_worked_2009  weeks_worked_2011  NORTH_EAST_79  \\\n",
       "0                NaN                NaN                NaN            1.0   \n",
       "1               52.0               52.0               52.0            1.0   \n",
       "2                0.0                NaN               52.0            1.0   \n",
       "3                NaN                NaN                NaN            1.0   \n",
       "4                NaN                NaN                NaN            1.0   \n",
       "\n",
       "   NORTH_CENTRAL_79  SOUTH_79  WEST_79  \n",
       "0               0.0       0.0      0.0  \n",
       "1               0.0       0.0      0.0  \n",
       "2               0.0       0.0      0.0  \n",
       "3               0.0       0.0      0.0  \n",
       "4               0.0       0.0      0.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nlsy79=pd.read_csv(\"https://raw.githubusercontent.com/bryangraham/Ec_141/master/Spring2019/Datasets/nlsy79extract.csv\")\n",
    "nlsy79.head() # Only shows the first 5 rows of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Drop any cases where `core_sample` equals zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Drop any units where `male` equals zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Drop any units where `year_born` is not 61, 62 or 63."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create a dummy variable called college which equals 1 if `HGC_Age28` is _greater than or equal to_ 16 and zero otherwise. Next drop any units where `HGC_Age28` is less than 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a variable called `earnings_in_2000` which is the average of `real_earnings_1997`, `real_earnings_1999`, `real_earnings_2001`, `real_earnings_2003`. When computing this variable average over all non-missing values; for example if earnings is observed in just two of the four years listed above, average over the two years it is observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Drop all variables except `live_with_mom_at_14` ,`live_with_dad_at_14` ,`usborn,hispanic` , `black` , `AFQT` , `HGC_Fath79` , `HGC_Moth79` , `college` and `earnings_in_2000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Finally retain only complete cases (you can use `“dropna()”` for this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Those units that remain constitute your estimation sample. Use “`describe()`” to print out some basic summary statistics for your estimation sample. Write a short paragraph about your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the average earnings premium due to college attendance\n",
    "A somewhat dated, although still useful, blog post on logistic regression using Python and\n",
    "statsmodels is available online [here](http://blog.yhat.com/posts/logistic-regression-python-rodeo.html).\n",
    "\n",
    "You might find this post useful for completing this portion of the problem set.\n",
    "\n",
    "1. Compute the logistic regression of `college` onto a constant and the other variables in your dataset (except for `earnings_in_2000`).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Compute the fitted values (“propensity scores”) associated with your regression fit, $\\hat{e}\\left(X_{i}\\right)$ for $i=1,\\ldots,N$.\n",
    " Is the overlap condition satisfied? Why? Present _graphical_ evidence for your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the IPW weights for average treatment effect (ATE) estimation as described in lecture and also Hirano & Imbens (2001). Compute the weighted least squares fit of `earnings_in_2000` onto a constant and college using these weights (this is a computational device which computes the IPW estimator described in lecture; you may use the WLS procedure in statsmodels for this step). Interpret the coefficient on college."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use the bootstrap procedure described in lecture to construct a confidence interval for the ATE. Use at least 500 bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Discuss your results. Is the selection on observables assumption reasonable? Why or why not? What additional data would you collect to improve your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
